{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Sneaker Data from the Stock X website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 2 components to this notebook:\n",
    "\n",
    "1. Using the individual shoe keys to scrape all the shoe info \n",
    "2. Using the shoe name search/ random shoe generator to get the price history for a specific shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import glob\n",
    "from urllib.request import Request, urlopen\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv with all the sneakers (used for debugging purposes)\n",
    "# second_path = r'/Users/gabbyvinco/Desktop/sneakers_df.csv'\n",
    "# round2 = pd.read_csv(second_path, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the csvs for the different sections of the Stock X website with the url additions\n",
    "path = r'/Users/gabbyvinco/Desktop/sneaker_csv'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "    \n",
    "frame = pd.concat(li, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take transpose of data frame\n",
    "frame = frame.T\n",
    "# set an index so the column with the keys is no longer the index\n",
    "frame = frame.reset_index()\n",
    "# rename column to 'urlKeys' and rename dataframe\n",
    "dataframe = frame.rename(columns={'index': 'urlKeys'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the urlKeys and inserting them in to th complete url with parameters\n",
    "full_urls = []\n",
    "\n",
    "for value in dataframe['urlKeys']:\n",
    "    full = 'https://stockx.com/api/products/'+value+'?includes=market,360&currency=EUR&country=IT'\n",
    "    #'https://stockx.com/api/products/'+value+\n",
    "        # this part is determining which file/shoe you want to work with \n",
    "    #'?includes=market,360&currency=EUR&country=IT' \n",
    "        # this part is basically a string that is being passed down to your web browser to the web server\n",
    "    # with this url we can send a GET request and fetch the information that is listed in the Inspect>Network>Preview\n",
    "    full_urls.append(full)\n",
    "    \n",
    "# create a new column with the full urls    \n",
    "dataframe['urlFull'] = full_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2471"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new list to hold the sneakers and all their information\n",
    "info = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shoe Info (getting the basic information regarding the shoe)\n",
    "\n",
    "Here we use the keys that we grabbed in the previous script. These keys when added to the query take you to the page for that specific shoe. From there we were able to make a request and gather information like the Stock X shoe identification number, brand, colorway, release date, retail price,official shoe name, volatility, change percentage, and marketed gender of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that loops through the full url list, extracts the variables that we want\n",
    "# and prints them out in a neat format\n",
    "\n",
    "def get_shoe_info(url_list):\n",
    "    for url in url_list:\n",
    "        headers = {\n",
    "            \"accept-encoding\": \"gzip, deflate, br\",\n",
    "            \"sec-fetch-mode\": \"cors\",\n",
    "            \"sec=fetch-site\": \"same-origin\",\n",
    "            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\",\n",
    "            \"x-requested-with\": \"XMLHttpRequest\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        product = response.json()[\"Product\"]\n",
    "        try:\n",
    "            id_num = product[\"id\"]\n",
    "        except:\n",
    "            print(\"no id\")\n",
    "            id_num = 0\n",
    "        try:\n",
    "            brand = product[\"brand\"]\n",
    "        except:\n",
    "            print(\"no brand\")\n",
    "            brand = 0\n",
    "        try:\n",
    "            colorway = product[\"colorway\"]\n",
    "        except:\n",
    "            print(\"no colorway\")\n",
    "            colorway = 0\n",
    "        try:    \n",
    "            release_date = product[\"releaseDate\"]\n",
    "        except:\n",
    "            print(\"no release date\")\n",
    "            release_date = 0\n",
    "        try:\n",
    "            retail_price = product[\"retailPrice\"]\n",
    "        except:\n",
    "            print(\"no retail price\")\n",
    "            retail_price = 0\n",
    "        try:\n",
    "            shoe_name = product[\"shoe\"]\n",
    "        except:\n",
    "            print(\"no shoe name\")\n",
    "            shoe_name = 0\n",
    "        try:\n",
    "            volatility = product[\"market\"][\"volatility\"]\n",
    "        except:\n",
    "            print(\"no volatility\")\n",
    "            volatility = 0\n",
    "        try:\n",
    "            change_percentage = product[\"market\"][\"changePercentage\"]\n",
    "        except:\n",
    "            print(\"no change percentage\")\n",
    "            change_percentage = 0\n",
    "        try:\n",
    "            gender = product[\"gender\"]\n",
    "        except:\n",
    "            print(\"no gender\")\n",
    "            gender = 0\n",
    "\n",
    "        info.append([id_num,\n",
    "                     brand,\n",
    "                     colorway,\n",
    "                     release_date,\n",
    "                     retail_price,\n",
    "                     shoe_name,\n",
    "                     volatility,\n",
    "                     change_percentage,\n",
    "                     gender])\n",
    "\n",
    "        print(\"shoe info added\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "no retail price\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no retail price\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "no retail price\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no retail price\n",
      "shoe info added\n",
      "no retail price\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "no release date\n",
      "shoe info added\n",
      "shoe info added\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabbyvinco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# (for personal use) brief explanation of __name__ == \"__main__\"\n",
    "# the global variable = __name__ and the entry point = __main__ (or the name that you import the module by)\n",
    "# so the code below this if statement will only run if the module == entry point to your program\n",
    "# it allows the code in the module to be importable by other modules without executing the code beneath the block on import\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    sys.exit(get_shoe_info(full_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add info into sneakers_df\n",
    "# sneaker_df = pd.DataFrame(info, columns = [\"ID\",\"Brand\", \"Colorway\",\"ReleaseDate\",\"RetailPrice\",\"Name\",\"Volatility\",\"ChangePercentage\",\"Gender\"])\n",
    "\n",
    "# re-ran the script because there was a timeout error\n",
    "# so here we just added to the point at which it was left off\n",
    "round2 = round2.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "round2.to_csv (r'/Users/gabbyvinco/Desktop/sneakers_df.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shoe Name Seach to generate a url for price history\n",
    "\n",
    "This portion was created with the intention to use with our time-series analysis. Here we have two methods as to which we can gather our price history info. \n",
    "1. By using the shoe search function where we can enter in the shoe name we are searching for, then select the colorway we want, and finally it will provide us with the \"sku_id\" which is the Stock X shoe identification number. Using this number we can continue and request the information from the price history plot.\n",
    "2. We use the random shoe generator which will provide us with \"sku_id\" for a random shoe on the Stock X website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sneaker dataset\n",
    "path = r'/Users/gabbyvinco/Desktop/Sneaker_Info_data.csv'\n",
    "sneaker_info_df = pd.read_csv(path, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the shoe you want to search? \n",
      "Yeezy 700 V3\n"
     ]
    }
   ],
   "source": [
    "# select shoe by name\n",
    "# make an input where the shoe name can be entered\n",
    "print(\"What is the name of the shoe you want to search? \")\n",
    "shoe_search = input()\n",
    "\n",
    "# make input lowercase to eliminate any variation in sizing\n",
    "shoe_search = shoe_search.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with all the sneaker names in the dataset ensure that they are all \n",
    "# lowercased so we can compare it with the input\n",
    "shoe_names = sneaker_info_df[\"Name\"].to_list()\n",
    "lower_names = []\n",
    "\n",
    "for i in shoe_names:\n",
    "    i = i.lower()\n",
    "    lower_names.append(i)\n",
    "\n",
    "# unique brands    \n",
    "unique_names = set(shoe_names)\n",
    "# print(unique_names)\n",
    "\n",
    "#unique brands by lowercase\n",
    "unique_lower_names = set(lower_names)\n",
    "# print(unique_lower_names)\n",
    "\n",
    "# capitalize the first letter of the searched term from the input\n",
    "shoe_search_capitalized = shoe_search.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found that shoe in our data.\n",
      "There are 9 different colorways of that shoe.\n",
      "     \n",
      "                           Colorway     Gender\n",
      "1721        Azareth/Azareth/Azareth        men\n",
      "1722              Alvah/Alvah/Alvah        men\n",
      "1726              Azael/Azael/Azael        men\n",
      "1728        Kyanite/Kyanite/Kyanite        men\n",
      "1733        Eremial/Eremial/Eremial        men\n",
      "1768  Safflower/Safflower/Safflower        men\n",
      "2070        Azareth/Azareth/Azareth    toddler\n",
      "2112  Safflower/Safflower/Safflower    toddler\n",
      "2167        Azareth/Azareth/Azareth  preschool\n",
      "     \n",
      "Please specify which colorway you would like: \n",
      "Azael/Azael/Azael\n",
      "     \n",
      "ID has been grabbed, proceed to make the request\n"
     ]
    }
   ],
   "source": [
    "if shoe_search in unique_lower_names:\n",
    "    print(\"We have found that shoe in our data.\")\n",
    "    \n",
    "    # count of how many types of that name shoe there are\n",
    "    count_of_name = sum(shoe_search in s for s in lower_names)\n",
    "    print(f'There are {count_of_name} different colorways of that shoe.')\n",
    "\n",
    "    # take the shoes of that name and display the colorways to choose from\n",
    "    sneaker_search_responses = sneaker_info_df.set_index([\"Name\"])\n",
    "    print(\"     \")\n",
    "    colorway_options = sneaker_info_df[sneaker_info_df[\"Name\"] == shoe_search_capitalized]\n",
    "    pd.set_option('display.max_rows', colorway_options.shape[0]+1)\n",
    "    print(colorway_options[[\"Colorway\",\"Gender\"]])\n",
    "    print(\"     \")\n",
    "    \n",
    "    # choose the colorway\n",
    "    print(\"Please specify which colorway you would like: \")\n",
    "    color_search = input()\n",
    "    print(\"     \")\n",
    "    \n",
    "    # take the selected colorway and output the ID number\n",
    "    selected_shoe = colorway_options[colorway_options[\"Colorway\"] == color_search]\n",
    "    sku_id = selected_shoe[\"ID\"]\n",
    "    print(\"ID has been grabbed, proceed to make the request\")\n",
    "#     print(id_num)\n",
    "\n",
    "else:\n",
    "    # error message if the shoe isnt in the dataset\n",
    "    print(\"We're sorry, the brand you entered wasn't found in our data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['176409b2-977e-4272-b02b-8fab93796e8d']\n"
     ]
    }
   ],
   "source": [
    "# to check if the id was grabbed\n",
    "print(sku_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the ID number from previous cell and insert it in the url\n",
    "search_url = \"https://stockx.com/api/products/\" + sku_id + \"/chart\"\n",
    "search_url = search_url.values[0]\n",
    "# display the entire id not just the first few characters\n",
    "pd.options.display.max_colwidth = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stockx.com/api/products/176409b2-977e-4272-b02b-8fab93796e8d/chart\n"
     ]
    }
   ],
   "source": [
    "# check the link generated\n",
    "print(search_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Shoe Generator to create url for price history\n",
    "\n",
    "This part uses a random number generator to then select a shoe out of the dataset and then provide a url for which we can then access the price history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2206"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the length of the dataset\n",
    "len(sneaker_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                              Jordan 1 Low\n",
      "Colorway    Sail/Gym Red-University Gold-Black\n",
      "Name: 411, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# create a random number generator to then select a shoe out of the dataset\n",
    "n = random.randint(0,2205)\n",
    "random_sneaker = sneaker_info_df.loc[n,:]\n",
    "print(random_sneaker[[\"Name\",\"Colorway\"]])\n",
    "random_id = random_sneaker[\"ID\"]\n",
    "# create the url using the id from the random generator\n",
    "random_url = \"https://stockx.com/api/products/\" + random_id + \"/chart\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stockx.com/api/products/7c79530c-fa82-463c-931c-f99d033102a7/chart\n"
     ]
    }
   ],
   "source": [
    "# check the link\n",
    "print(random_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price History Function (Getting the data from the interactive plots)\n",
    "\n",
    "This portion now uses the url from either the shoe search fucntion or the random shoe generator to access the price history plot on the Stock X website. This information is visible on the website in an interactive plot, however we were able to make a request and gather all of the price history information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow us to control the days for which we want the price history information\n",
    "day_ago = datetime.today()- timedelta(days=1)\n",
    "day_choose = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_history(url_with_id, day_get):\n",
    "\n",
    "    params = {\n",
    "        \"start_date\": \"all\",\n",
    "        \"end_date\": day_get,\n",
    "        \"intervals\": \"100\",\n",
    "        \"format\": \"highstock\",\n",
    "        \"currency\": \"EUR\",\n",
    "        \"country\": \"IT\"\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"accept-encoding\": \"gzip, deflate\",\n",
    "        \"sec-fetch-mode\": \"cors\",\n",
    "        \"sec-fetch-site\": \"same-origin\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\",\n",
    "        \"x-requested-with\": \"XMLHttpRequest\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url_with_id, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    price_history = response.json()[\"series\"][0][\"data\"]\n",
    "    \n",
    "    y = []\n",
    "    for timestamp, price in response.json()[\"series\"][0][\"data\"]:\n",
    "        date = datetime.utcfromtimestamp(int(timestamp) // 1000)\n",
    "        print(f\"[{date}]: €{price}\")\n",
    "        # append to list so data frame can be created\n",
    "        y.append([date, price])\n",
    "    \n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't forget to pass in the url variable (either search_url OR random_url)\n",
    "You must use one or the other, but not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-05 03:06:30]: €666\n",
      "[2019-12-10 07:17:06]: €643\n",
      "[2019-12-15 11:27:43]: €427\n",
      "[2019-12-20 15:38:19]: €404\n",
      "[2019-12-25 19:48:56]: €414\n",
      "[2019-12-30 23:59:32]: €410\n",
      "[2020-01-05 04:10:09]: €413\n",
      "[2020-01-10 08:20:45]: €417\n",
      "[2020-01-15 12:31:22]: €416\n",
      "[2020-01-20 16:41:59]: €412\n",
      "[2020-01-25 20:52:35]: €437\n",
      "[2020-01-31 01:03:12]: €467\n",
      "[2020-02-05 05:13:48]: €474\n",
      "[2020-02-10 09:24:25]: €480\n",
      "[2020-02-15 13:35:01]: €499\n",
      "[2020-02-20 17:45:38]: €501\n",
      "[2020-02-25 21:56:14]: €504\n",
      "[2020-03-02 02:06:51]: €509\n",
      "[2020-03-07 06:17:28]: €516\n",
      "[2020-03-12 10:28:04]: €492\n",
      "[2020-03-17 14:38:41]: €485\n",
      "[2020-03-22 18:49:17]: €479\n",
      "[2020-03-27 22:59:54]: €499\n",
      "[2020-04-02 03:10:30]: €513\n",
      "[2020-04-07 07:21:07]: €510\n",
      "[2020-04-12 11:31:44]: €525\n",
      "[2020-04-17 15:42:20]: €546\n",
      "[2020-04-22 19:52:57]: €573\n",
      "[2020-04-28 00:03:33]: €578\n",
      "[2020-05-03 04:14:10]: €573\n",
      "[2020-05-08 08:24:46]: €577\n",
      "[2020-05-13 12:35:23]: €575\n",
      "[2020-05-18 16:45:59]: €591\n",
      "[2020-05-23 20:56:36]: €622\n",
      "[2020-05-29 01:07:13]: €655\n",
      "[2020-06-03 05:17:49]: €624\n",
      "[2020-06-08 09:28:26]: €637\n",
      "[2020-06-13 13:39:02]: €638\n",
      "[2020-06-18 17:49:39]: €648\n",
      "[2020-06-23 22:00:15]: €646\n",
      "[2020-06-29 02:10:52]: €653\n",
      "[2020-07-04 06:21:28]: €640\n",
      "[2020-07-09 10:32:05]: €658\n",
      "[2020-07-14 14:42:42]: €684\n",
      "[2020-07-19 18:53:18]: €685\n",
      "[2020-07-24 23:03:55]: €684\n",
      "[2020-07-30 03:14:31]: €707\n",
      "[2020-08-04 07:25:08]: €690\n",
      "[2020-08-09 11:35:44]: €686\n",
      "[2020-08-14 15:46:21]: €677\n",
      "[2020-08-19 19:56:58]: €685\n",
      "[2020-08-25 00:07:34]: €715\n",
      "[2020-08-30 04:18:11]: €703\n",
      "[2020-09-04 08:28:47]: €708\n",
      "[2020-09-09 12:39:24]: €702\n",
      "[2020-09-14 16:50:00]: €716\n",
      "[2020-09-19 21:00:37]: €668\n",
      "[2020-09-25 01:11:13]: €684\n",
      "[2020-09-30 05:21:50]: €679\n",
      "[2020-10-05 09:32:27]: €689\n",
      "[2020-10-10 13:43:03]: €655\n",
      "[2020-10-15 17:53:40]: €638\n",
      "[2020-10-20 22:04:16]: €684\n",
      "[2020-10-26 02:14:53]: €673\n",
      "[2020-10-31 06:25:29]: €592\n",
      "[2020-11-05 10:36:06]: €635\n",
      "[2020-11-10 14:46:42]: €618\n",
      "[2020-11-15 18:57:19]: €628\n",
      "[2020-11-20 23:07:56]: €640\n",
      "[2020-11-26 03:18:32]: €619\n",
      "[2020-12-01 07:29:09]: €668\n",
      "[2020-12-06 11:39:45]: €648\n",
      "[2020-12-11 15:50:22]: €621\n",
      "[2020-12-16 20:00:58]: €633\n",
      "[2020-12-22 00:11:35]: €633\n",
      "[2020-12-27 04:22:12]: €633\n",
      "[2021-01-01 08:32:48]: €628\n",
      "[2021-01-06 12:43:25]: €619\n",
      "[2021-01-11 16:54:01]: €609\n",
      "[2021-01-16 21:04:38]: €623\n",
      "[2021-01-22 01:15:14]: €613\n",
      "[2021-01-27 05:25:51]: €610\n",
      "[2021-02-01 09:36:27]: €633\n",
      "[2021-02-06 13:47:04]: €601\n",
      "[2021-02-11 17:57:41]: €634\n",
      "[2021-02-16 22:08:17]: €597\n",
      "[2021-02-22 02:18:54]: €632\n",
      "[2021-02-27 06:29:30]: €653\n",
      "[2021-03-04 10:40:07]: €644\n",
      "[2021-03-09 14:50:43]: €619\n",
      "[2021-03-14 19:01:20]: €619\n",
      "[2021-03-19 23:11:56]: €631\n",
      "[2021-03-25 03:22:33]: €634\n",
      "[2021-03-30 07:33:10]: €630\n",
      "[2021-04-04 11:43:46]: €634\n",
      "[2021-04-09 15:54:23]: €650\n",
      "[2021-04-14 20:04:59]: €668\n",
      "[2021-04-20 00:15:36]: €628\n",
      "[2021-04-25 04:26:12]: €636\n",
      "[2021-04-30 08:36:49]: €640\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabbyvinco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    sys.exit(get_price_history(search_url, day_choose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the y list\n",
    "price_history_df = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-21 19:54:25</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-26 12:38:00</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-31 05:21:35</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-04 22:05:10</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-09 14:48:45</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-04-12 00:55:06</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021-04-16 17:38:41</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2021-04-21 10:22:16</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2021-04-26 03:05:51</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2021-04-30 19:49:26</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0     1\n",
       "0  2020-01-21 19:54:25  1041\n",
       "1  2020-01-26 12:38:00  1041\n",
       "2  2020-01-31 05:21:35  1041\n",
       "3  2020-02-04 22:05:10  1041\n",
       "4  2020-02-09 14:48:45  1041\n",
       "..                 ...   ...\n",
       "95 2021-04-12 00:55:06   359\n",
       "96 2021-04-16 17:38:41   359\n",
       "97 2021-04-21 10:22:16   358\n",
       "98 2021-04-26 03:05:51   363\n",
       "99 2021-04-30 19:49:26   360\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a csv file\n",
    "# price_history_df.to_csv (r'/Users/gabbyvinco/Desktop/sneakers_df.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
